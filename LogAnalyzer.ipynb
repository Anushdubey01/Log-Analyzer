{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Log Analyzer** ðŸ“Š\n",
    "\n",
    "This Python script processes web server log files to extract and analyze key information, such as request counts, frequently accessed endpoints, and suspicious activity (e.g., failed login attempts). It uses a more structured approach, leveraging data classes and advanced error handling.\n",
    "\n",
    "---\n",
    "\n",
    "##### Objective\n",
    "\n",
    "The goal of this script is to:\n",
    "1. Count Requests per IP Address\n",
    "2. Identify the Most Frequently Accessed Endpoint\n",
    "3. Detect Suspicious Activity (e.g., failed login attempts)\n",
    "\n",
    "---\n",
    "\n",
    "##### Features\n",
    "\n",
    "- Count Requests per IP: Tracks how many requests each IP address makes.\n",
    "- Most Accessed Endpoint: Identifies which endpoint is accessed the most.\n",
    "- Suspicious Activity Detection: Flags IP addresses that have more than a specified threshold of failed login attempts (HTTP status `401` or \"Invalid credentials\").\n",
    "- CSV Export: Results are saved into a CSV file (`log_analysis_results.csv`).\n",
    "- Logging: Detailed logging of all actions and any issues encountered during the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "##### Requirements\n",
    "\n",
    "- Python 3.8 or later.\n",
    "- Libraries: Python standard library (`re`, `csv`, `sys`, `logging`, `pathlib`, `collections`, `typing`, `dataclasses`).\n",
    "\n",
    "---\n",
    "\n",
    "##### Usage\n",
    "\n",
    "###### Prepare Your Log File\n",
    "- Download or create a sample log file (`sample.log`). A sample log is included with this project.\n",
    "\n",
    "###### Run the Script\n",
    "To analyze the log file, run the script from the terminal:\n",
    "\n",
    "```bash\n",
    "python3 log_analysis_script.py\n",
    "```\n",
    "\n",
    "###### Results\n",
    "The script will display the following analysis results in the terminal:\n",
    "- IP Request Counts: A count of requests per IP address.\n",
    "- Most Accessed Endpoint: The endpoint with the highest number of accesses.\n",
    "- Suspicious Activities: A list of IP addresses with suspicious failed login attempts.\n",
    "\n",
    "Additionally, the results will be exported to `log_analysis_results.csv`, containing:\n",
    "- IP Request Counts\n",
    "- Most Accessed Endpoint\n",
    "- Suspicious Activity\n",
    "\n",
    "---\n",
    "\n",
    "##### Code Overview\n",
    "\n",
    "###### LogEntry Class\n",
    "\n",
    "A data class representing a parsed log entry:\n",
    "```python\n",
    "@dataclass\n",
    "class LogEntry:\n",
    "    ip_address: str\n",
    "    method: str\n",
    "    endpoint: str\n",
    "    status_code: str\n",
    "    message: Optional[str] = None\n",
    "```\n",
    "\n",
    "###### LogAnalyzer Class\n",
    "\n",
    "The core class for processing log files and generating reports:\n",
    "- parse_log_file: Reads and parses the log file line by line.\n",
    "- _process_log_entry: Tracks IP request counts, endpoint access counts, and failed login attempts.\n",
    "- get_most_accessed_endpoint: Returns the most accessed endpoint and its access count.\n",
    "- get_suspicious_activities: Flags IP addresses with suspicious login activity based on failed login attempts.\n",
    "- display_results: Displays the analysis results in the terminal.\n",
    "- export_to_csv: Exports the results to a CSV file.\n",
    "\n",
    "###### Main Execution Function\n",
    "\n",
    "The `main()` function initializes the `LogAnalyzer`, processes the log file, and displays the results:\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    try:\n",
    "        log_file_path = Path('sample.log')\n",
    "        failed_login_threshold = 10\n",
    "\n",
    "        analyzer = LogAnalyzer(\n",
    "            log_file_path,\n",
    "            failed_login_threshold,\n",
    "            log_level=logging.INFO\n",
    "        )\n",
    "\n",
    "        analyzer.parse_log_file()\n",
    "        analyzer.display_results()\n",
    "        analyzer.export_to_csv()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Unhandled exception: {e}\")\n",
    "        sys.exit(1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### Log Format\n",
    "\n",
    "The script expects the log file to follow a common NGINX or Apache log format:\n",
    "\n",
    "```\n",
    "<IP Address> - - [<Date>] \"<HTTP Method> <Endpoint> HTTP/1.1\" <Status Code> <Response Size> \"<Message>\"\n",
    "```\n",
    "\n",
    "Sample log entries:\n",
    "```\n",
    "192.168.1.1 - - [03/Dec/2024:10:12:34 +0000] \"GET /home HTTP/1.1\" 200 512\n",
    "203.0.113.5 - - [03/Dec/2024:10:12:35 +0000] \"POST /login HTTP/1.1\" 401 128 \"Invalid credentials\"\n",
    "10.0.0.2 - - [03/Dec/2024:10:12:36 +0000] \"GET /about HTTP/1.1\" 200 256\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### CSV Output Format\n",
    "\n",
    "The script generates a CSV file with the following structure:\n",
    "\n",
    "###### IP Request Counts\n",
    "| IP Address       | Request Count |\n",
    "|------------------|---------------|\n",
    "| 192.168.1.1      | 234           |\n",
    "| 203.0.113.5      | 187           |\n",
    "\n",
    "###### Most Accessed Endpoint\n",
    "| Endpoint     | Access Count |\n",
    "|--------------|--------------|\n",
    "| /home        | 403          |\n",
    "\n",
    "###### Suspicious Activity\n",
    "| IP Address    | Failed Login Count |\n",
    "|---------------|--------------------|\n",
    "| 192.168.1.100 | 56                 |\n",
    "| 203.0.113.34  | 12                 |\n",
    "\n",
    "---\n",
    "\n",
    "##### Logging\n",
    "\n",
    "Logging is configured to log messages both to the console and to a file (`log_analysis.log`):\n",
    "- INFO: Logs regular operations.\n",
    "- WARNING: Logs lines that couldn't be parsed.\n",
    "- ERROR: Logs errors when processing individual log entries.\n",
    "- CRITICAL: Logs critical errors, such as issues opening the log file or unhandled exceptions.\n",
    "\n",
    "---\n",
    "\n",
    "Submitted by: Anush Dubey (anushdubey881@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NT0Tyt1Kj77",
    "outputId": "6645b164-37bb-4192-aeba-19e64d4fdde4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "VRV SECURITY - LOG ANALYSIS REPORT\n",
      "==================================================\n",
      "\n",
      "--- IP Request Counts ---\n",
      "203.0.113.5              8 requests\n",
      "198.51.100.23            8 requests\n",
      "192.168.1.1              7 requests\n",
      "10.0.0.2                 6 requests\n",
      "192.168.1.100            5 requests\n",
      "\n",
      "--- Most Accessed Endpoint ---\n",
      "/login (Accessed 13 times)\n",
      "\n",
      "--- Suspicious Activities ---\n",
      "No suspicious activities detected.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"\n",
    "    Structured data class to represent a parsed log entry.\n",
    "    Allows for more robust and type-safe log parsing.\n",
    "    \"\"\"\n",
    "    ip_address: str\n",
    "    method: str\n",
    "    endpoint: str\n",
    "    status_code: str\n",
    "    message: Optional[str] = None\n",
    "\n",
    "class LogAnalyzer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        log_file_path: Path,\n",
    "        failed_login_threshold: int = 10,\n",
    "        log_level: int = logging.INFO\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Log Analyzer with advanced configuration.\n",
    "\n",
    "        :param log_file_path: Path to the log file\n",
    "        :param failed_login_threshold: Threshold for suspicious login attempts\n",
    "        :param log_level: Logging verbosity level\n",
    "        \"\"\"\n",
    "        # Configure logging\n",
    "        logging.basicConfig(\n",
    "            level=log_level,\n",
    "            format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "            handlers=[\n",
    "                logging.StreamHandler(sys.stderr),\n",
    "                logging.FileHandler('log_analysis.log', mode='w')\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Validate input file\n",
    "        self.log_file_path = Path(log_file_path)\n",
    "        if not self.log_file_path.is_file():\n",
    "            self.logger.error(f\"Log file not found: {self.log_file_path}\")\n",
    "            raise FileNotFoundError(f\"Log file not found: {self.log_file_path}\")\n",
    "\n",
    "        # Configuration parameters\n",
    "        self.failed_login_threshold = failed_login_threshold\n",
    "\n",
    "        # Analysis storage\n",
    "        self.parsed_entries: List[LogEntry] = []\n",
    "        self.ip_request_counts: Counter = Counter()\n",
    "        self.endpoint_access_counts: Counter = Counter()\n",
    "        self.failed_login_attempts: Counter = Counter()\n",
    "\n",
    "    def parse_log_file(self) -> None:\n",
    "        \"\"\"\n",
    "        Advanced log file parsing with comprehensive error handling.\n",
    "        \"\"\"\n",
    "        log_pattern = re.compile(\n",
    "            r'^(\\d+\\.\\d+\\.\\d+\\.\\d+).*\"(\\w+)\\s+([^\\s]+)\\s+[^\"]*\"\\s+(\\d+)\\s*(.*)$'\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            with open(self.log_file_path, 'r') as log_file:\n",
    "                for line_num, line in enumerate(log_file, 1):\n",
    "                    try:\n",
    "                        match = log_pattern.match(line.strip())\n",
    "                        if match:\n",
    "                            groups = match.groups()\n",
    "                            log_entry = LogEntry(\n",
    "                                ip_address=groups[0],\n",
    "                                method=groups[1],\n",
    "                                endpoint=groups[2],\n",
    "                                status_code=groups[3],\n",
    "                                message=groups[4] or None\n",
    "                            )\n",
    "                            self._process_log_entry(log_entry)\n",
    "                        else:\n",
    "                            self.logger.warning(f\"Unparseable log line {line_num}: {line.strip()}\")\n",
    "                    except Exception as entry_error:\n",
    "                        self.logger.error(f\"Error processing line {line_num}: {entry_error}\")\n",
    "\n",
    "        except IOError as file_error:\n",
    "            self.logger.critical(f\"File reading error: {file_error}\")\n",
    "            raise\n",
    "\n",
    "    def _process_log_entry(self, entry: LogEntry) -> None:\n",
    "        \"\"\"\n",
    "        Process individual log entries and track metrics.\n",
    "\n",
    "        :param entry: Parsed log entry\n",
    "        \"\"\"\n",
    "        # Track IP requests\n",
    "        self.ip_request_counts[entry.ip_address] += 1\n",
    "\n",
    "        # Track endpoint access\n",
    "        self.endpoint_access_counts[entry.endpoint] += 1\n",
    "\n",
    "        # Detect suspicious login attempts\n",
    "        if (entry.status_code == '401' or\n",
    "            (entry.message and 'Invalid credentials' in entry.message)):\n",
    "            self.failed_login_attempts[entry.ip_address] += 1\n",
    "\n",
    "    def get_most_accessed_endpoint(self) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Find the most frequently accessed endpoint.\n",
    "\n",
    "        :return: Tuple of (endpoint, access_count)\n",
    "        \"\"\"\n",
    "        return self.endpoint_access_counts.most_common(1)[0] if self.endpoint_access_counts else (\"N/A\", 0)\n",
    "\n",
    "    def get_suspicious_activities(self) -> List[Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Identify IP addresses with suspicious login activity.\n",
    "\n",
    "        :return: List of (IP, failed_login_count) tuples exceeding threshold\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (ip, count)\n",
    "            for ip, count in self.failed_login_attempts.items()\n",
    "            if count > self.failed_login_threshold\n",
    "        ]\n",
    "\n",
    "    def display_results(self) -> None:\n",
    "        \"\"\"\n",
    "        Display comprehensive analysis results with formatting.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"VRV SECURITY - LOG ANALYSIS REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # IP Request Counts\n",
    "        print(\"\\n--- IP Request Counts ---\")\n",
    "        for ip, count in self.ip_request_counts.most_common():\n",
    "            print(f\"{ip:<20} {count:>5} requests\")\n",
    "\n",
    "        # Most Accessed Endpoint\n",
    "        endpoint, access_count = self.get_most_accessed_endpoint()\n",
    "        print(f\"\\n--- Most Accessed Endpoint ---\")\n",
    "        print(f\"{endpoint} (Accessed {access_count} times)\")\n",
    "\n",
    "        # Suspicious Activities\n",
    "        suspicious_ips = self.get_suspicious_activities()\n",
    "        print(\"\\n--- Suspicious Activities ---\")\n",
    "        if suspicious_ips:\n",
    "            for ip, count in suspicious_ips:\n",
    "                print(f\"{ip:<20} {count:>3} failed login attempts\")\n",
    "        else:\n",
    "            print(\"No suspicious activities detected.\")\n",
    "\n",
    "    def export_to_csv(\n",
    "        self,\n",
    "        output_file: Path = Path('log_analysis_results.csv')\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Export analysis results to a structured CSV file.\n",
    "\n",
    "        :param output_file: Path to the output CSV file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(output_file, 'w', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "\n",
    "                # IP Request Counts\n",
    "                csv_writer.writerow([\"IP Request Counts\"])\n",
    "                csv_writer.writerow([\"IP Address\", \"Request Count\"])\n",
    "                for ip, count in self.ip_request_counts.most_common():\n",
    "                    csv_writer.writerow([ip, count])\n",
    "\n",
    "                # Most Accessed Endpoint\n",
    "                csv_writer.writerow([])\n",
    "                csv_writer.writerow([\"Most Accessed Endpoint\"])\n",
    "                csv_writer.writerow([\"Endpoint\", \"Access Count\"])\n",
    "                endpoint, access_count = self.get_most_accessed_endpoint()\n",
    "                csv_writer.writerow([endpoint, access_count])\n",
    "\n",
    "                # Suspicious Activities\n",
    "                csv_writer.writerow([])\n",
    "                csv_writer.writerow([\"Suspicious Activities\"])\n",
    "                csv_writer.writerow([\"IP Address\", \"Failed Login Count\"])\n",
    "                for ip, count in self.get_suspicious_activities():\n",
    "                    csv_writer.writerow([ip, count])\n",
    "\n",
    "            self.logger.info(f\"Results exported to {output_file}\")\n",
    "\n",
    "        except IOError as e:\n",
    "            self.logger.error(f\"CSV export failed: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function with robust error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configurable parameters\n",
    "        log_file_path = Path('sample.log')\n",
    "        failed_login_threshold = 10\n",
    "\n",
    "        # Initialize and run log analyzer\n",
    "        analyzer = LogAnalyzer(\n",
    "            log_file_path,\n",
    "            failed_login_threshold,\n",
    "            log_level=logging.INFO\n",
    "        )\n",
    "\n",
    "        # Process log file\n",
    "        analyzer.parse_log_file()\n",
    "\n",
    "        # Display results\n",
    "        analyzer.display_results()\n",
    "\n",
    "        # Export to CSV\n",
    "        analyzer.export_to_csv()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Unhandled exception: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
